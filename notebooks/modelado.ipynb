{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37f2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a probar modelos de ML\n",
    "#leamos x_train, y_train, x_test, y_test\n",
    "import pandas as pd\n",
    "x_train = pd.read_csv(\"../data/processed/splits/x_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/splits/y_train.csv\")\n",
    "x_test = pd.read_csv(\"../data/processed/splits/x_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/splits/y_test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ef59d",
   "metadata": {},
   "source": [
    "Antes de buscar cuál es el mejor modelo entre los candidatos sugeridos por la consigna, vamos a seleccionar variables usando el feature importance de un Random Forest Regressor. \n",
    "\n",
    "Vamos a buscar los mejores hiperparametros para un Random Forest Regressor con Optuna, después vamos a obtener su feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45689bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:41,348] A new study created in memory with name: no-name-160b5992-e5c5-40e1-8f7c-d986fe297c1f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (667, 174), Valid: (166, 174), Test: (356, 174)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 9.11314e+07:   2%|▏         | 1/60 [00:00<00:30,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:41,870] Trial 0 finished with value: 91131365.09297095 and parameters: {'max_depth': 6, 'max_features': 'log2', 'bootstrap': True, 'n_estimators': 582, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_samples': 0.6521211214797689}. Best is trial 0 with value: 91131365.09297095.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.20066e+07:   3%|▎         | 2/60 [00:02<01:15,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:43,730] Trial 1 finished with value: 32006561.444609974 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1294, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_samples': 0.9744427686266666}. Best is trial 1 with value: 32006561.444609974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.20066e+07:   5%|▌         | 3/60 [00:04<01:26,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:45,488] Trial 2 finished with value: 386686448.7126678 and parameters: {'max_depth': None, 'max_features': 0.7, 'bootstrap': True, 'n_estimators': 1136, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_samples': 0.9847923138822793}. Best is trial 1 with value: 32006561.444609974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.20066e+07:   7%|▋         | 4/60 [00:05<01:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:46,480] Trial 3 finished with value: 194388454.81355616 and parameters: {'max_depth': 6, 'max_features': 0.7, 'bootstrap': True, 'n_estimators': 705, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_samples': 0.9010984903770198}. Best is trial 1 with value: 32006561.444609974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:   8%|▊         | 5/60 [00:07<01:25,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:48,482] Trial 4 finished with value: 21574652.75085198 and parameters: {'max_depth': 6, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1322, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  10%|█         | 6/60 [00:10<01:59,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:51,972] Trial 5 finished with value: 45936876.0670716 and parameters: {'max_depth': 24, 'max_features': 1.0, 'bootstrap': False, 'n_estimators': 970, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  12%|█▏        | 7/60 [00:11<01:36,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:52,962] Trial 6 finished with value: 98918595.4653639 and parameters: {'max_depth': 24, 'max_features': 'log2', 'bootstrap': False, 'n_estimators': 1655, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  13%|█▎        | 8/60 [00:13<01:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:54,507] Trial 7 finished with value: 438748994.84502393 and parameters: {'max_depth': 32, 'max_features': 1.0, 'bootstrap': True, 'n_estimators': 1119, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_samples': 0.5599326836668415}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  15%|█▌        | 9/60 [00:14<01:18,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:55,634] Trial 8 finished with value: 80266335.26361331 and parameters: {'max_depth': 6, 'max_features': 'sqrt', 'bootstrap': True, 'n_estimators': 1297, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_samples': 0.6393232321183058}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  17%|█▋        | 10/60 [00:14<01:04,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:56,347] Trial 9 finished with value: 101707354.28673944 and parameters: {'max_depth': 24, 'max_features': 'log2', 'bootstrap': False, 'n_estimators': 1164, 'min_samples_split': 3, 'min_samples_leaf': 17}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  18%|█▊        | 11/60 [00:15<00:49,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:56,758] Trial 10 finished with value: 937775611.9064847 and parameters: {'max_depth': 10, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 232, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  20%|██        | 12/60 [00:18<01:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:27:59,546] Trial 11 finished with value: 840513978.1027015 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1721, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  22%|██▏       | 13/60 [00:19<01:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:01,257] Trial 12 finished with value: 266251215.36423978 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1554, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_samples': 0.8157762107920377}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  23%|██▎       | 14/60 [00:22<01:31,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:04,144] Trial 13 finished with value: 562703861.8532597 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1973, 'min_samples_split': 8, 'min_samples_leaf': 13}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  25%|██▌       | 15/60 [00:24<01:25,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:05,814] Trial 14 finished with value: 23667957.73377746 and parameters: {'max_depth': 10, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1372, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_samples': 0.8030513372748733}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  27%|██▋       | 16/60 [00:25<01:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:06,781] Trial 15 finished with value: 44323702.053796224 and parameters: {'max_depth': 10, 'max_features': 'sqrt', 'bootstrap': False, 'n_estimators': 1475, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  28%|██▊       | 17/60 [00:26<01:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:08,012] Trial 16 finished with value: 585341756.3809729 and parameters: {'max_depth': 10, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 819, 'min_samples_split': 15, 'min_samples_leaf': 13}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  30%|███       | 18/60 [00:28<01:11,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:10,169] Trial 17 finished with value: 295644752.0053748 and parameters: {'max_depth': None, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1945, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_samples': 0.7698777899432435}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  32%|███▏      | 19/60 [00:31<01:18,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:12,568] Trial 18 finished with value: 788466041.0365621 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1428, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  33%|███▎      | 20/60 [00:33<01:18,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:14,622] Trial 19 finished with value: 173887260.0101111 and parameters: {'max_depth': 6, 'max_features': 0.7, 'bootstrap': True, 'n_estimators': 1813, 'min_samples_split': 10, 'min_samples_leaf': 13, 'max_samples': 0.8412617858914677}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  35%|███▌      | 21/60 [00:36<01:25,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:17,357] Trial 20 finished with value: 1457776058.4115067 and parameters: {'max_depth': 10, 'max_features': 1.0, 'bootstrap': False, 'n_estimators': 936, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  37%|███▋      | 22/60 [00:38<01:22,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:19,523] Trial 21 finished with value: 23342587.370842613 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1339, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9829705066274331}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  38%|███▊      | 23/60 [00:39<01:14,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:21,126] Trial 22 finished with value: 29055951.071683746 and parameters: {'max_depth': 10, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1356, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_samples': 0.7004831188261248}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  40%|████      | 24/60 [00:41<01:10,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:22,938] Trial 23 finished with value: 21844734.857036844 and parameters: {'max_depth': 6, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1621, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.8976469851027725}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  42%|████▏     | 25/60 [00:43<01:06,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:24,704] Trial 24 finished with value: 387960905.3125559 and parameters: {'max_depth': 6, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1608, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_samples': 0.9106412457318777}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  43%|████▎     | 26/60 [00:44<01:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:26,245] Trial 25 finished with value: 101695932.20152697 and parameters: {'max_depth': 6, 'max_features': 'sqrt', 'bootstrap': True, 'n_estimators': 1779, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_samples': 0.8952128953015633}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  45%|████▌     | 27/60 [00:46<00:58,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:27,960] Trial 26 finished with value: 119195387.74885143 and parameters: {'max_depth': 6, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1523, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_samples': 0.9960572597563107}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  47%|████▋     | 28/60 [00:48<00:56,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:29,750] Trial 27 finished with value: 22792165.27098287 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1206, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9394554332606727}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  48%|████▊     | 29/60 [00:49<00:51,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:31,194] Trial 28 finished with value: 470002774.39184093 and parameters: {'max_depth': 6, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1017, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  50%|█████     | 30/60 [00:50<00:37,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:31,499] Trial 29 finished with value: 83943553.43364623 and parameters: {'max_depth': 6, 'max_features': 'log2', 'bootstrap': True, 'n_estimators': 307, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_samples': 0.8745333408003872}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  52%|█████▏    | 31/60 [00:50<00:30,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:32,020] Trial 30 finished with value: 112599001.45841199 and parameters: {'max_depth': None, 'max_features': 'sqrt', 'bootstrap': True, 'n_estimators': 550, 'min_samples_split': 8, 'min_samples_leaf': 11, 'max_samples': 0.9289162588973211}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  53%|█████▎    | 32/60 [00:52<00:35,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:33,806] Trial 31 finished with value: 22513695.414131496 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1184, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9520591631670037}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  55%|█████▌    | 33/60 [00:54<00:37,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:35,512] Trial 32 finished with value: 34678925.315212496 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1204, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9406656381106677}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  57%|█████▋    | 34/60 [00:55<00:37,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:37,066] Trial 33 finished with value: 137709296.8824897 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1248, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_samples': 0.8559516490576821}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  58%|█████▊    | 35/60 [00:57<00:39,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:38,990] Trial 34 finished with value: 37359437.12320003 and parameters: {'max_depth': 16, 'max_features': 0.7, 'bootstrap': True, 'n_estimators': 1060, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9428313502418081}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  60%|██████    | 36/60 [00:58<00:34,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:40,066] Trial 35 finished with value: 392693194.1026976 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 888, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_samples': 0.7415196031316402}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  62%|██████▏   | 37/60 [01:02<00:47,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:43,533] Trial 36 finished with value: 40728169.222680174 and parameters: {'max_depth': 32, 'max_features': 1.0, 'bootstrap': True, 'n_estimators': 1456, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.9484789369537848}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  63%|██████▎   | 38/60 [01:03<00:37,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:44,482] Trial 37 finished with value: 211641347.41236693 and parameters: {'max_depth': 6, 'max_features': 0.7, 'bootstrap': True, 'n_estimators': 751, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_samples': 0.8583148459360613}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  65%|██████▌   | 39/60 [01:03<00:29,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:45,227] Trial 38 finished with value: 81727919.08083594 and parameters: {'max_depth': 24, 'max_features': 'log2', 'bootstrap': False, 'n_estimators': 1246, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  67%|██████▋   | 40/60 [01:05<00:27,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:46,462] Trial 39 finished with value: 38782438.53222158 and parameters: {'max_depth': None, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1102, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.5116937679835183}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  68%|██████▊   | 41/60 [01:06<00:23,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:47,353] Trial 40 finished with value: 546300093.0332705 and parameters: {'max_depth': 6, 'max_features': 1.0, 'bootstrap': True, 'n_estimators': 571, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_samples': 0.8106536771742798}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  70%|███████   | 42/60 [01:08<00:26,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:49,410] Trial 41 finished with value: 23172302.977461178 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1355, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.999566332813127}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  72%|███████▏  | 43/60 [01:09<00:25,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:51,029] Trial 42 finished with value: 34082416.40869321 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1162, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_samples': 0.9559786861208105}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  73%|███████▎  | 44/60 [01:11<00:27,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:53,247] Trial 43 finished with value: 136804450.02211252 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1631, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_samples': 0.9028096353726814}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 2.15747e+07:  75%|███████▌  | 45/60 [01:13<00:27,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:55,224] Trial 44 finished with value: 22700856.88074646 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': True, 'n_estimators': 1271, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_samples': 0.9949195028750147}. Best is trial 4 with value: 21574652.75085198.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  77%|███████▋  | 46/60 [01:16<00:29,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:57,998] Trial 45 finished with value: 21121668.424161486 and parameters: {'max_depth': 16, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1270, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  78%|███████▊  | 47/60 [01:17<00:22,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:28:58,957] Trial 46 finished with value: 70771338.53499818 and parameters: {'max_depth': 24, 'max_features': 'log2', 'bootstrap': False, 'n_estimators': 1559, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  80%|████████  | 48/60 [01:20<00:24,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:01,552] Trial 47 finished with value: 21729051.711156562 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1294, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  82%|████████▏ | 49/60 [01:22<00:24,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:04,185] Trial 48 finished with value: 478788322.29468006 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1425, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  83%|████████▎ | 50/60 [01:23<00:18,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:05,276] Trial 49 finished with value: 124444986.37709656 and parameters: {'max_depth': 32, 'max_features': 'sqrt', 'bootstrap': False, 'n_estimators': 1714, 'min_samples_split': 11, 'min_samples_leaf': 15}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  85%|████████▌ | 51/60 [01:25<00:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:07,316] Trial 50 finished with value: 21233709.034017753 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1036, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  87%|████████▋ | 52/60 [01:27<00:15,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:09,255] Trial 51 finished with value: 21229382.639991242 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1021, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  88%|████████▊ | 53/60 [01:29<00:13,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:11,077] Trial 52 finished with value: 631052820.378111 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 1015, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  90%|█████████ | 54/60 [01:31<00:11,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:12,851] Trial 53 finished with value: 21778364.72771814 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 882, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  92%|█████████▏| 55/60 [01:33<00:08,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:14,496] Trial 54 finished with value: 21161612.575719804 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 837, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  93%|█████████▎| 56/60 [01:34<00:06,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:16,141] Trial 55 finished with value: 949848092.2805636 and parameters: {'max_depth': 32, 'max_features': 0.7, 'bootstrap': False, 'n_estimators': 749, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 45. Best value: 2.11217e+07:  95%|█████████▌| 57/60 [01:35<00:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:17,342] Trial 56 finished with value: 498964761.6358956 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 633, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 45 with value: 21121668.424161486.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 57. Best value: 2.10334e+07:  97%|█████████▋| 58/60 [01:37<00:03,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:19,182] Trial 57 finished with value: 21033399.11844295 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 970, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 57 with value: 21033399.11844295.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 57. Best value: 2.10334e+07:  98%|█████████▊| 59/60 [01:40<00:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:21,861] Trial 58 finished with value: 43578676.26883574 and parameters: {'max_depth': 32, 'max_features': 1.0, 'bootstrap': False, 'n_estimators': 816, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 57 with value: 21033399.11844295.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 57. Best value: 2.10334e+07: 100%|██████████| 60/60 [01:42<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:23,527] Trial 59 finished with value: 801422544.4119908 and parameters: {'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 965, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 57 with value: 21033399.11844295.\n",
      "\n",
      "=== Mejores hiperparámetros (VALID) ===\n",
      "{'max_depth': 32, 'max_features': 0.5, 'bootstrap': False, 'n_estimators': 970, 'min_samples_split': 11, 'min_samples_leaf': 4}\n",
      "Mejor RMSE valid: 21033399.1184\n",
      "\n",
      "=== Métricas en TEST ===\n",
      "MSE : 14,377,245.74\n",
      "RMSE: 14,377,245.74\n",
      "MAE : 2,866.04\n",
      "R²  : 0.5933\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Optuna para RandomForestRegressor (split temporal) + \"pruning\" pasivo\n",
    "# ==============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "SEED = 42\n",
    "VAL_FRAC = 0.20    # último 20% del train como valid\n",
    "N_TRIALS = 60      # subí/bajá según tiempo\n",
    "\n",
    "# --------- Split temporal (train -> train/valid ; test queda intacto) ---------\n",
    "X_train_all = x_train.copy()\n",
    "y_train_all = y_train.copy()\n",
    "X_test = x_test.copy()\n",
    "y_test = y_test.copy()\n",
    "\n",
    "n = len(X_train_all)\n",
    "n_val = int(np.floor(n * VAL_FRAC))\n",
    "n_tr = n - n_val\n",
    "X_tr, y_tr = X_train_all.iloc[:n_tr], y_train_all[:n_tr]\n",
    "X_val, y_val = X_train_all.iloc[n_tr:], y_train_all[n_tr:]\n",
    "\n",
    "print(f\"Train: {X_tr.shape}, Valid: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# --------- Función objetivo ---------\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Espacio de búsqueda (robusto para RF sklearn)\n",
    "    max_depth_choice = trial.suggest_categorical(\"max_depth\", [None, 6, 10, 16, 24, 32])\n",
    "    max_features_choice = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.5, 0.7, 1.0])\n",
    "    bootstrap_choice = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "        \"criterion\": \"squared_error\",\n",
    "        \"max_depth\": max_depth_choice,                 # None = sin límite\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        \"max_features\": max_features_choice,           # fracción o estrategia\n",
    "        \"bootstrap\": bootstrap_choice,\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    # Si se usa bootstrap, probar muestreo parcial de filas\n",
    "    if bootstrap_choice:\n",
    "        params[\"max_samples\"] = trial.suggest_float(\"max_samples\", 0.5, 1.0)\n",
    "\n",
    "    # Modelo\n",
    "    model = RandomForestRegressor(**params)\n",
    "\n",
    "    # Entrenar y evaluar en VALID (métrica a minimizar: RMSE)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    rmse_val = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "    # Registrar también como “valor intermedio” (no habrá pruning real, pero queda logueado)\n",
    "    trial.report(rmse_val, step=0)\n",
    "    # if trial.should_prune():   # en RF no habrá pasos intermedios útiles\n",
    "    #     raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return rmse_val\n",
    "\n",
    "# --------- Estudio Optuna ---------\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=TPESampler(seed=SEED),\n",
    "    pruner=MedianPruner(n_warmup_steps=5)  # no tendrá efecto real aquí, pero se deja por consistencia\n",
    ")\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n=== Mejores hiperparámetros (VALID) ===\")\n",
    "print(study.best_params)\n",
    "print(f\"Mejor RMSE valid: {study.best_value:.4f}\")\n",
    "\n",
    "# --------- Re-entrenar con los mejores params (train+valid) ---------\n",
    "best_params = study.best_params.copy()\n",
    "best_model = RandomForestRegressor(**best_params, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "best_model.fit(X_train_all, y_train_all)\n",
    "\n",
    "# --------- Evaluación en TEST ---------\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "mse  = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = mean_squared_error(y_test, y_pred_test)\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "r2   = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n=== Métricas en TEST ===\")\n",
    "print(f\"MSE : {mse:,.2f}\")\n",
    "print(f\"RMSE: {rmse:,.2f}\")\n",
    "print(f\"MAE : {mae:,.2f}\")\n",
    "print(f\"R²  : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0743b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas en TEST del mejor modelo entrenado manualmente ===\n",
      "MSE : 11,980,515.69\n",
      "RMSE: 11,980,515.69\n",
      "MAE : 2,684.17\n",
      "R²  : 0.6611\n",
      "Feature importances:\n",
      "                    feature  importance\n",
      "40                Frio (Kw)    0.529431\n",
      "36            Sala Maq (Kw)    0.198587\n",
      "167   Frio_roll_mean_7_lag1    0.118802\n",
      "32            Envasado (Kw)    0.017051\n",
      "169  Frio_roll_mean_14_lag1    0.013890\n",
      "35           Servicios (Kw)    0.013222\n",
      "171  Frio_roll_mean_28_lag1    0.004571\n",
      "160                 mes_cos    0.003345\n",
      "45           KW Gral Planta    0.003033\n",
      "13        ET Servicios / Hl    0.002859\n",
      "11             ET Bodega/Hl    0.002751\n",
      "6              EE Frio / Hl    0.002404\n",
      "41     Pta Agua / Eflu (Kw)    0.002376\n",
      "5          EE Sala Maq / Hl    0.002209\n",
      "168    Frio_roll_std_7_lag1    0.002168\n",
      "26            Hl Cerveza L4    0.002089\n",
      "43          Resto Serv (Kw)    0.001996\n",
      "34             Linea 3 (Kw)    0.001928\n",
      "42           Prod Agua (Kw)    0.001887\n",
      "164         Frio_diff7_lag1    0.001867\n"
     ]
    }
   ],
   "source": [
    "\"\"\"El mejor modelo fue RFRegressor con los siguientes hiperparámetros:\n",
    "    {'max_depth': 16, 'max_features': 1.0, 'bootstrap': True, 'n_estimators': 1183, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.8654367662002576}\"\"\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "#Entrenemos un modelo con esos hiperparámetros\n",
    "\n",
    "best_model = RandomForestRegressor(\n",
    "    n_estimators=1183,\n",
    "    max_depth=16,\n",
    "    max_features=1.0,\n",
    "    bootstrap=True,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_samples=0.8654367662002576,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "x_train_ready = pd.DataFrame(pt.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test_ready = pd.DataFrame(pt.transform(x_test), columns=x_test.columns)\n",
    "\n",
    "best_model.fit(x_train_ready, y_train)\n",
    "y_pred_test = best_model.predict(x_test_ready)\n",
    "mse  = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = mean_squared_error(y_test, y_pred_test)\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "r2   = r2_score(y_test, y_pred_test)\n",
    "print(\"\\n=== Métricas en TEST del mejor modelo entrenado manualmente ===\")\n",
    "print(f\"MSE : {mse:,.2f}\")\n",
    "print(f\"RMSE: {rmse:,.2f}\")\n",
    "print(f\"MAE : {mae:,.2f}\")\n",
    "print(f\"R²  : {r2:.4f}\")\n",
    "\n",
    "#gracias a este random forest vamos a definir nuestras variables más relevantes\n",
    "\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = x_train.columns\n",
    "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "feature_importances = feature_importances[:20]\n",
    "print(\"Feature importances:\")\n",
    "print(feature_importances)\n",
    "x_train = x_train[feature_importances['feature']]\n",
    "x_test = x_test[feature_importances['feature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eb7d1e",
   "metadata": {},
   "source": [
    "Ahora vamos a seleccionar las primeras 20 variables y buscar el modelo que minimice el MAE en nuestro test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18d3c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:46,624] A new study created in memory with name: ridge_opt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4240\n",
      "[LightGBM] [Info] Number of data points in the train set: 667, number of used features: 20\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 28568.025112\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4856\n",
      "[LightGBM] [Info] Number of data points in the train set: 833, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 28296.922269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-17 00:29:49,199] Trial 0 finished with value: 21524.070042132178 and parameters: {'alpha': 0.0006967758838912295}. Best is trial 0 with value: 21524.070042132178.\n",
      "[I 2025-11-17 00:29:51,160] Trial 1 finished with value: 21422.525152250037 and parameters: {'alpha': 0.07582035756045312}. Best is trial 1 with value: 21422.525152250037.\n",
      "[I 2025-11-17 00:29:53,164] Trial 2 finished with value: 20601.465554133567 and parameters: {'alpha': 0.9950422811956947}. Best is trial 2 with value: 20601.465554133567.\n",
      "[I 2025-11-17 00:29:54,756] Trial 3 finished with value: 15644.4931506505 and parameters: {'alpha': 27.120661603216256}. Best is trial 3 with value: 15644.4931506505.\n",
      "[I 2025-11-17 00:29:54,770] Trial 4 finished with value: 15493.942881579922 and parameters: {'alpha': 29.14739282239711}. Best is trial 4 with value: 15493.942881579922.\n",
      "[I 2025-11-17 00:29:54,785] Trial 5 finished with value: 13424.59431679433 and parameters: {'alpha': 88.39345499443026}. Best is trial 5 with value: 13424.59431679433.\n",
      "[I 2025-11-17 00:29:54,809] Trial 6 finished with value: 16964.835892771083 and parameters: {'alpha': 14.22263222034829}. Best is trial 5 with value: 13424.59431679433.\n",
      "[I 2025-11-17 00:29:54,823] Trial 7 finished with value: 15442.067285681405 and parameters: {'alpha': 29.87873872417645}. Best is trial 5 with value: 13424.59431679433.\n",
      "[I 2025-11-17 00:29:54,837] Trial 8 finished with value: 16044.034263917134 and parameters: {'alpha': 22.370995707397736}. Best is trial 5 with value: 13424.59431679433.\n",
      "[I 2025-11-17 00:29:54,851] Trial 9 finished with value: 12426.274576737287 and parameters: {'alpha': 163.69072757633165}. Best is trial 9 with value: 12426.274576737287.\n",
      "[I 2025-11-17 00:29:54,866] Trial 10 finished with value: 21429.044169403885 and parameters: {'alpha': 0.07049893400797627}. Best is trial 9 with value: 12426.274576737287.\n",
      "[I 2025-11-17 00:29:54,881] Trial 11 finished with value: 10273.845422437345 and parameters: {'alpha': 749.0347948753098}. Best is trial 11 with value: 10273.845422437345.\n",
      "[I 2025-11-17 00:29:54,897] Trial 12 finished with value: 10276.015949532586 and parameters: {'alpha': 747.5910805078449}. Best is trial 11 with value: 10273.845422437345.\n",
      "[I 2025-11-17 00:29:54,912] Trial 13 finished with value: 9971.085425907622 and parameters: {'alpha': 998.4250132951128}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:54,928] Trial 14 finished with value: 10147.128923366758 and parameters: {'alpha': 841.0337071804207}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:54,943] Trial 15 finished with value: 19909.677784812888 and parameters: {'alpha': 2.1847684750276684}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:54,961] Trial 16 finished with value: 21523.30628470045 and parameters: {'alpha': 0.0011720564957557397}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:54,975] Trial 17 finished with value: 21514.16464872169 and parameters: {'alpha': 0.007014916974584003}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:54,991] Trial 18 finished with value: 19173.003993991217 and parameters: {'alpha': 4.119308124084905}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,007] Trial 19 finished with value: 11291.072265659233 and parameters: {'alpha': 343.6666650942253}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,022] Trial 20 finished with value: 21524.987078010752 and parameters: {'alpha': 0.00012895565508778866}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,049] Trial 21 finished with value: 10216.854141566251 and parameters: {'alpha': 788.3905765358498}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,064] Trial 22 finished with value: 12588.253884191596 and parameters: {'alpha': 147.452215404138}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,080] Trial 23 finished with value: 10649.433789112283 and parameters: {'alpha': 548.0047265276849}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,096] Trial 24 finished with value: 13556.25394416216 and parameters: {'alpha': 81.94380591033432}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,111] Trial 25 finished with value: 9988.566390999684 and parameters: {'alpha': 980.6442572780464}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,127] Trial 26 finished with value: 18456.581718483405 and parameters: {'alpha': 6.558317669598594}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,144] Trial 27 finished with value: 21060.016258103038 and parameters: {'alpha': 0.4284675572626837}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,159] Trial 28 finished with value: 11938.446129464857 and parameters: {'alpha': 224.449881913819}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,175] Trial 29 finished with value: 13643.058973132307 and parameters: {'alpha': 78.00830085182528}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,190] Trial 30 finished with value: 21467.04440309405 and parameters: {'alpha': 0.040223702241624484}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,206] Trial 31 finished with value: 10074.306286449206 and parameters: {'alpha': 901.4226326018046}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,234] Trial 32 finished with value: 11566.89271977221 and parameters: {'alpha': 285.9202000678223}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,252] Trial 33 finished with value: 10178.799114395602 and parameters: {'alpha': 816.3769773106567}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,277] Trial 34 finished with value: 14112.552013403078 and parameters: {'alpha': 59.73576219732495}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,306] Trial 35 finished with value: 11712.272991113092 and parameters: {'alpha': 259.900596016188}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,335] Trial 36 finished with value: 18114.51818047811 and parameters: {'alpha': 7.962008854154915}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,350] Trial 37 finished with value: 14462.908020796614 and parameters: {'alpha': 49.09044995559986}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,376] Trial 38 finished with value: 12590.326313865613 and parameters: {'alpha': 147.25516693695414}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,391] Trial 39 finished with value: 10075.39844076327 and parameters: {'alpha': 900.4788971989847}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,407] Trial 40 finished with value: 16360.063134437887 and parameters: {'alpha': 19.1769746891262}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,424] Trial 41 finished with value: 9982.509779296752 and parameters: {'alpha': 986.7218687601558}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,440] Trial 42 finished with value: 11481.190338754792 and parameters: {'alpha': 302.61858167393154}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,455] Trial 43 finished with value: 10924.535435455022 and parameters: {'alpha': 443.83627047409243}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,471] Trial 44 finished with value: 12819.43643391377 and parameters: {'alpha': 127.14471373042538}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,486] Trial 45 finished with value: 14891.07073557479 and parameters: {'alpha': 39.18845108407478}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,503] Trial 46 finished with value: 10935.024470389304 and parameters: {'alpha': 440.41907251335505}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,519] Trial 47 finished with value: 10134.45083118166 and parameters: {'alpha': 851.1262391401912}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,534] Trial 48 finished with value: 10027.791402760768 and parameters: {'alpha': 943.2525445930108}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,550] Trial 49 finished with value: 12492.117263829898 and parameters: {'alpha': 156.86519513843018}. Best is trial 13 with value: 9971.085425907622.\n",
      "[I 2025-11-17 00:29:55,562] A new study created in memory with name: lasso_opt\n",
      "[I 2025-11-17 00:29:55,597] Trial 0 finished with value: 21505.07007203436 and parameters: {'alpha': 0.7127808317630138}. Best is trial 0 with value: 21505.07007203436.\n",
      "[I 2025-11-17 00:29:55,631] Trial 1 finished with value: 21525.13647111283 and parameters: {'alpha': 0.00012454653170250525}. Best is trial 0 with value: 21505.07007203436.\n",
      "[I 2025-11-17 00:29:55,655] Trial 2 finished with value: 21069.375185504832 and parameters: {'alpha': 30.752740990687375}. Best is trial 2 with value: 21069.375185504832.\n",
      "[I 2025-11-17 00:29:55,679] Trial 3 finished with value: 21286.193964864604 and parameters: {'alpha': 12.508725353294315}. Best is trial 2 with value: 21069.375185504832.\n",
      "[I 2025-11-17 00:29:55,714] Trial 4 finished with value: 21523.119966175185 and parameters: {'alpha': 0.07098929417343369}. Best is trial 2 with value: 21069.375185504832.\n",
      "[I 2025-11-17 00:29:55,871] Trial 5 finished with value: 21523.9343084976 and parameters: {'alpha': 0.0423633449848474}. Best is trial 2 with value: 21069.375185504832.\n",
      "[I 2025-11-17 00:29:55,906] Trial 6 finished with value: 21520.206747366974 and parameters: {'alpha': 0.1735296159319302}. Best is trial 2 with value: 21069.375185504832.\n",
      "[I 2025-11-17 00:29:55,930] Trial 7 finished with value: 20486.57589747443 and parameters: {'alpha': 90.39821052108634}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:55,964] Trial 8 finished with value: 21521.159423597244 and parameters: {'alpha': 0.13991792361310987}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:55,990] Trial 9 finished with value: 21322.87246313722 and parameters: {'alpha': 9.736885139666471}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:56,027] Trial 10 finished with value: 21525.098305802338 and parameters: {'alpha': 0.0014676707116951118}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:56,043] Trial 11 finished with value: 20529.130801104384 and parameters: {'alpha': 86.20287034411155}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:56,068] Trial 12 finished with value: 20639.293507261587 and parameters: {'alpha': 75.37979571128753}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:56,094] Trial 13 finished with value: 21454.112974970267 and parameters: {'alpha': 2.654978816527735}. Best is trial 7 with value: 20486.57589747443.\n",
      "[I 2025-11-17 00:29:56,119] Trial 14 finished with value: 20399.107632410676 and parameters: {'alpha': 99.19954379124833}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,145] Trial 15 finished with value: 21426.123791867005 and parameters: {'alpha': 3.8298416977754104}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,191] Trial 16 finished with value: 21525.011835853493 and parameters: {'alpha': 0.004507612006275911}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,227] Trial 17 finished with value: 21502.564462804323 and parameters: {'alpha': 0.8040248149644853}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,253] Trial 18 finished with value: 21237.438653144847 and parameters: {'alpha': 15.70623986578129}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,278] Trial 19 finished with value: 20472.766714611433 and parameters: {'alpha': 91.77849694530295}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,316] Trial 20 finished with value: 21476.18487229427 and parameters: {'alpha': 1.7827063454825947}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,341] Trial 21 finished with value: 20686.921581411225 and parameters: {'alpha': 70.73769751566145}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,367] Trial 22 finished with value: 21244.034576112805 and parameters: {'alpha': 15.28596804411256}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,393] Trial 23 finished with value: 20978.593172395813 and parameters: {'alpha': 40.79948274506197}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,418] Trial 24 finished with value: 21369.418426006545 and parameters: {'alpha': 6.863176798559107}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,444] Trial 25 finished with value: 20399.9736522612 and parameters: {'alpha': 99.11124946849006}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,470] Trial 26 finished with value: 21108.928248842796 and parameters: {'alpha': 26.303944840631246}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,516] Trial 27 finished with value: 21524.688009076228 and parameters: {'alpha': 0.01587944199423121}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,552] Trial 28 finished with value: 21513.751406060037 and parameters: {'alpha': 0.400142429363143}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,588] Trial 29 finished with value: 21497.879322465258 and parameters: {'alpha': 0.9747438004865894}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,614] Trial 30 finished with value: 21404.45694158785 and parameters: {'alpha': 4.8599746681762905}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,640] Trial 31 finished with value: 20525.936175450748 and parameters: {'alpha': 86.51182915021826}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,665] Trial 32 finished with value: 21022.43223267162 and parameters: {'alpha': 36.130110995511565}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,713] Trial 33 finished with value: 21525.133457540687 and parameters: {'alpha': 0.0002304422840557647}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,739] Trial 34 finished with value: 21088.77092018122 and parameters: {'alpha': 28.567004291338}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,766] Trial 35 finished with value: 20411.78361373289 and parameters: {'alpha': 97.90620821444865}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,792] Trial 36 finished with value: 21190.040368997114 and parameters: {'alpha': 19.0186983807186}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,818] Trial 37 finished with value: 21346.682600253655 and parameters: {'alpha': 8.197076871548285}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,846] Trial 38 finished with value: 20991.267929608257 and parameters: {'alpha': 39.49832108450528}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,874] Trial 39 finished with value: 20897.14896912111 and parameters: {'alpha': 49.43105864109493}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,910] Trial 40 finished with value: 21470.107051974697 and parameters: {'alpha': 2.0153245595050513}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,938] Trial 41 finished with value: 21213.128717536758 and parameters: {'alpha': 17.32243281175803}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,966] Trial 42 finished with value: 20499.257955959747 and parameters: {'alpha': 89.1381352166138}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:56,993] Trial 43 finished with value: 20403.592555838204 and parameters: {'alpha': 98.7393713831147}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:57,019] Trial 44 finished with value: 20938.195963646216 and parameters: {'alpha': 45.03087270469793}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:57,046] Trial 45 finished with value: 21352.019250576785 and parameters: {'alpha': 7.850392036092327}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:57,061] Trial 46 finished with value: 20432.18445165125 and parameters: {'alpha': 95.8428988366574}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:57,086] Trial 47 finished with value: 21107.21779572285 and parameters: {'alpha': 26.491473889508683}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:57,131] Trial 48 finished with value: 21517.117184745515 and parameters: {'alpha': 0.28231883067448565}. Best is trial 14 with value: 20399.107632410676.\n",
      "[I 2025-11-17 00:29:57,157] Trial 49 finished with value: 21294.11179857053 and parameters: {'alpha': 11.838715912684158}. Best is trial 14 with value: 20399.107632410676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Mejor modelo seleccionado por MAE en Test: RandomForest (Test MAE=2656.5378)\n",
      "\n",
      "==== Listo ====\n",
      "- Logs: results\\experiment_logs.csv\n",
      "- Resumen: results\\experiment_summary_20251117_002929.md\n",
      "- Gráficos y FI en: results/\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Experiments: Tracking, Evaluation & Plots\n",
    "# ============================================\n",
    "import os, json, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Modelos y utils\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "SEED = 42\n",
    "VAL_FRAC = 0.20\n",
    "N_TRIALS = 50   # Optuna\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "LOG_PATH = RESULTS_DIR / \"experiment_logs.csv\"\n",
    "TS = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def metrics_dict(y_true, y_pred):\n",
    "    return {\n",
    "        \"mae\":  mean_absolute_error(y_true, y_pred),\n",
    "        \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)), # squared=False devuelve RMSE\n",
    "        \"mse\":  mean_squared_error(y_true, y_pred),\n",
    "        \"r2\":   r2_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "def append_log(row: dict, log_path: Path = LOG_PATH):\n",
    "    row = row.copy()\n",
    "    row[\"timestamp\"] = datetime.now().isoformat()\n",
    "    df_row = pd.DataFrame([row])\n",
    "    if not log_path.exists():\n",
    "        df_row.to_csv(log_path, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(log_path, index=False, mode=\"a\", header=False)\n",
    "\n",
    "def plot_pred_vs_true(y_true, y_pred, title, out_path):\n",
    "    plt.figure()\n",
    "    plt.scatter(y_true, y_pred, s=8)\n",
    "    minv = np.min([y_true.min(), y_pred.min()])\n",
    "    maxv = np.max([y_true.max(), y_pred.max()])\n",
    "    plt.plot([minv, maxv], [minv, maxv], 'r--')\n",
    "    plt.xlabel(\"Valor real\")\n",
    "    plt.ylabel(\"Predicción\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_residuals(y_true, y_pred, title, out_path_scatter, out_path_hist):\n",
    "    resid = y_pred - y_true\n",
    "    # Residual vs Pred\n",
    "    plt.figure()\n",
    "    plt.scatter(y_pred, resid, s=8)\n",
    "    plt.axhline(0, color='r', linestyle='--')\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Residuo\")\n",
    "    plt.title(title + \" - Residual vs Pred\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path_scatter, dpi=150)\n",
    "    plt.close()\n",
    "    # Histograma\n",
    "    plt.figure()\n",
    "    plt.hist(resid, bins=30, edgecolor='k')\n",
    "    plt.xlabel(\"Residuo\")\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.title(title + \" - Hist Residuales\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path_hist, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def save_feature_importance(model, feature_names, out_csv, out_png, top_k=30):\n",
    "    # Pipeline handling: get the final estimator\n",
    "    if isinstance(model, Pipeline):\n",
    "        est = model.steps[-1][1]\n",
    "        # Coefs for linear in pipeline\n",
    "        if hasattr(est, \"coef_\"):\n",
    "            coef = np.ravel(est.coef_)\n",
    "            imp = pd.DataFrame({\"feature\": feature_names, \"importance\": np.abs(coef)})\n",
    "        elif hasattr(est, \"feature_importances_\"):\n",
    "            importances = est.feature_importances_\n",
    "            imp = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "        else:\n",
    "             imp = pd.DataFrame({\"feature\": feature_names, \"importance\": np.zeros(len(feature_names))})\n",
    "    else:\n",
    "        # Standard models\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            importances = model.feature_importances_\n",
    "            imp = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "        elif hasattr(model, \"coef_\"):\n",
    "            coef = np.ravel(model.coef_)\n",
    "            imp = pd.DataFrame({\"feature\": feature_names, \"importance\": np.abs(coef)})\n",
    "        else:\n",
    "            # XGB/LGBM wrappers usually have feature_importances_\n",
    "            try:\n",
    "                importances = model.get_booster().get_score(importance_type=\"gain\")\n",
    "                # XGB keys might not match feature names exactly if not set, mapping is safer but simple dict works often\n",
    "                imp = pd.DataFrame({\"feature\": list(importances.keys()),\n",
    "                                    \"importance\": list(importances.values())})\n",
    "            except Exception:\n",
    "                imp = pd.DataFrame({\"feature\": feature_names, \"importance\": np.zeros(len(feature_names))})\n",
    "\n",
    "    imp = imp.sort_values(\"importance\", ascending=False)\n",
    "    imp.to_csv(out_csv, index=False)\n",
    "\n",
    "    top = imp.head(top_k)\n",
    "    plt.figure(figsize=(8, max(3, 0.28*len(top))))\n",
    "    plt.barh(top[\"feature\"][::-1], top[\"importance\"][::-1])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.title(\"Feature importance (top)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def refit_full_for_test(model, X_tr, y_tr, X_val=None, y_val=None):\n",
    "    \"\"\"\n",
    "    Refit en todo el train usando mejor n_estimators si hay early stopping.\n",
    "    \"\"\"\n",
    "    # XGB\n",
    "    if isinstance(model, xgb.XGBRegressor):\n",
    "        best_n = getattr(model, \"best_iteration\", None)\n",
    "        params = model.get_params()\n",
    "        if best_n is not None:\n",
    "            params[\"n_estimators\"] = best_n\n",
    "        m = xgb.XGBRegressor(**params)\n",
    "        m.fit(X_tr, y_tr)  # full train\n",
    "        return m\n",
    "\n",
    "    # LGBM\n",
    "    if isinstance(model, LGBMRegressor):\n",
    "        best_n = getattr(model, \"best_iteration_\", None)\n",
    "        params = model.get_params()\n",
    "        if best_n is not None and best_n > 0:\n",
    "            params[\"n_estimators\"] = best_n\n",
    "        m = LGBMRegressor(**params)\n",
    "        m.fit(X_tr, y_tr)\n",
    "        return m\n",
    "\n",
    "    # Otros: re-usa el modelo tal cual y refitea\n",
    "    # Si es pipeline, clone o crear nuevo\n",
    "    from sklearn.base import clone\n",
    "    m = clone(model)\n",
    "    m.fit(X_tr, y_tr)\n",
    "    return m\n",
    "\n",
    "def write_summary_md(log_path: Path, summary_path: Path):\n",
    "    df = pd.read_csv(log_path)\n",
    "    # MODIFICADO: Orden por MAE de Test\n",
    "    df = df.sort_values(\"test_mae\").reset_index(drop=True)\n",
    "    lines = []\n",
    "    lines.append(f\"# Experiment Summary — {datetime.now().isoformat()}\\n\")\n",
    "    lines.append(\"## Top 10 por MAE de Test\\n\")\n",
    "    cols = [\"timestamp\",\"model_name\",\"test_mae\",\"test_rmse\",\"test_r2\",\"val_rmse\",\"val_mae\"]\n",
    "    lines.append(df[cols].head(10).to_markdown(index=False))\n",
    "    lines.append(\"\\n## Espacios de búsqueda declarados\\n\")\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.notna(row.get(\"search_space_str\", \"\")) and str(row.get(\"search_space_str\", \"\")).strip():\n",
    "            lines.append(f\"- **{row['model_name']}**: `{row['search_space_str']}`\")\n",
    "    lines.append(\"\\n## Justificación\\n\")\n",
    "    lines.append(\"- **CRITERIO DE SELECCIÓN: Menor MAE en Test.**\")\n",
    "    lines.append(\"- Se reportan métricas en test del modelo refiteado en todo el train.\")\n",
    "    lines.append(\"- La elección queda respaldada por `results/experiment_logs.csv` y este resumen.\")\n",
    "    summary_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "# =========================\n",
    "# 0) Se espera que tengas x_train, y_train, x_test, y_test en memoria\n",
    "# =========================\n",
    "\n",
    "# =========================\n",
    "# 1) PowerTransformer como baseline\n",
    "# =========================\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "X_train_ready = pd.DataFrame(pt.fit_transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "X_test_ready  = pd.DataFrame(pt.transform(x_test),      columns=x_test.columns,  index=x_test.index)\n",
    "\n",
    "# Split temporal interno para validación\n",
    "n = len(X_train_ready)\n",
    "n_val = int(np.floor(n * VAL_FRAC))\n",
    "n_tr = n - n_val\n",
    "X_tr, y_tr = X_train_ready.iloc[:n_tr], np.ravel(y_train.iloc[:n_tr])\n",
    "X_val, y_val = X_train_ready.iloc[n_tr:], np.ravel(y_train.iloc[n_tr:])\n",
    "X_full, y_full = X_train_ready, np.ravel(y_train)\n",
    "\n",
    "# Para logs\n",
    "base_log_ctx = {\n",
    "    \"n_train\": len(X_tr),\n",
    "    \"n_val\": len(X_val),\n",
    "    \"n_full_train\": len(X_full),\n",
    "    \"n_test\": len(X_test_ready),\n",
    "    \"n_features\": X_train_ready.shape[1],\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 2) Modelos y búsquedas\n",
    "# =========================\n",
    "all_results = []\n",
    "\n",
    "# (a) RandomForest — baseline\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=1183,\n",
    "    max_depth=16,\n",
    "    max_features=1.0,\n",
    "    bootstrap=True,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_samples=0.8654367662002576,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_tr, y_tr)\n",
    "y_val_pred = rf.predict(X_val)\n",
    "val_metrics = metrics_dict(y_val, y_val_pred)\n",
    "\n",
    "rf_refit = refit_full_for_test(rf, X_full, y_full)\n",
    "y_test_pred = rf_refit.predict(X_test_ready)\n",
    "test_metrics = metrics_dict(np.ravel(y_test), y_test_pred)\n",
    "\n",
    "append_log({\n",
    "    **base_log_ctx,\n",
    "    \"model_name\": \"RandomForest\",\n",
    "    \"params_json\": json.dumps(rf.get_params()),\n",
    "    \"search_space_str\": \"Fixed params (baseline)\",\n",
    "    \"val_mae\": val_metrics[\"mae\"],\n",
    "    \"val_rmse\": val_metrics[\"rmse\"],\n",
    "    \"val_r2\": val_metrics[\"r2\"],\n",
    "    \"test_mae\": test_metrics[\"mae\"],\n",
    "    \"test_rmse\": test_metrics[\"rmse\"],\n",
    "    \"test_r2\": test_metrics[\"r2\"],\n",
    "}, LOG_PATH)\n",
    "# MODIFICADO: Guardamos test_metrics[\"mae\"] para comparar\n",
    "all_results.append((\"RandomForest\", test_metrics[\"mae\"], rf, rf_refit, y_val_pred, y_test_pred))\n",
    "\n",
    "# (b) XGBoost — early stopping en validación\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=5000, learning_rate=0.02, max_depth=8,\n",
    "    subsample=0.8, colsample_bytree=0.8, reg_alpha=0.0, reg_lambda=1.0,\n",
    "    min_child_weight=1.0, random_state=SEED, tree_method=\"hist\", n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False) # verbose false para limpiar salida\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "val_metrics = metrics_dict(y_val, y_val_pred)\n",
    "\n",
    "xgb_refit = refit_full_for_test(xgb_model, X_full, y_full)\n",
    "y_test_pred = xgb_refit.predict(X_test_ready)\n",
    "test_metrics = metrics_dict(np.ravel(y_test), y_test_pred)\n",
    "\n",
    "append_log({\n",
    "    **base_log_ctx,\n",
    "    \"model_name\": \"XGBoost\",\n",
    "    \"params_json\": json.dumps(xgb_model.get_params()),\n",
    "    \"search_space_str\": \"Fixed params; early_stopping_rounds=200\",\n",
    "    \"val_mae\": val_metrics[\"mae\"],\n",
    "    \"val_rmse\": val_metrics[\"rmse\"],\n",
    "    \"val_r2\": val_metrics[\"r2\"],\n",
    "    \"test_mae\": test_metrics[\"mae\"],\n",
    "    \"test_rmse\": test_metrics[\"rmse\"],\n",
    "    \"test_r2\": test_metrics[\"r2\"],\n",
    "}, LOG_PATH)\n",
    "# MODIFICADO: Guardamos test_metrics[\"mae\"]\n",
    "all_results.append((\"XGBoost\", test_metrics[\"mae\"], xgb_model, xgb_refit, y_val_pred, y_test_pred))\n",
    "\n",
    "# (c) LightGBM — early stopping en validación\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=5000, learning_rate=0.02, num_leaves=127, max_depth=-1,\n",
    "    subsample=0.8, colsample_bytree=0.8, reg_alpha=0.0, reg_lambda=1.0,\n",
    "    min_child_samples=20, random_state=SEED, n_jobs=-1\n",
    ")\n",
    "lgbm_model.fit(X_tr, y_tr,\n",
    "               eval_set=[(X_val, y_val)],\n",
    "               callbacks=[early_stopping(stopping_rounds=200, verbose=False)])\n",
    "y_val_pred = lgbm_model.predict(X_val)\n",
    "val_metrics = metrics_dict(y_val, y_val_pred)\n",
    "\n",
    "lgbm_refit = refit_full_for_test(lgbm_model, X_full, y_full)\n",
    "y_test_pred = lgbm_refit.predict(X_test_ready)\n",
    "test_metrics = metrics_dict(np.ravel(y_test), y_test_pred)\n",
    "\n",
    "append_log({\n",
    "    **base_log_ctx,\n",
    "    \"model_name\": \"LightGBM\",\n",
    "    \"params_json\": json.dumps(lgbm_model.get_params()),\n",
    "    \"search_space_str\": \"Fixed params; early_stopping_rounds=200\",\n",
    "    \"val_mae\": val_metrics[\"mae\"],\n",
    "    \"val_rmse\": val_metrics[\"rmse\"],\n",
    "    \"val_r2\": val_metrics[\"r2\"],\n",
    "    \"test_mae\": test_metrics[\"mae\"],\n",
    "    \"test_rmse\": test_metrics[\"rmse\"],\n",
    "    \"test_r2\": test_metrics[\"r2\"],\n",
    "}, LOG_PATH)\n",
    "# MODIFICADO: Guardamos test_metrics[\"mae\"]\n",
    "all_results.append((\"LightGBM\", test_metrics[\"mae\"], lgbm_model, lgbm_refit, y_val_pred, y_test_pred))\n",
    "\n",
    "# (d) Ridge — Optuna (CV TimeSeriesSplit)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "def ridge_objective(trial: optuna.Trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-4, 1e3, log=True)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(alpha=alpha, random_state=SEED))\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X_full, y_full, cv=tscv,\n",
    "                             scoring=\"neg_mean_absolute_error\", n_jobs=-1) # Ojo: Optuna optimiza validación interna\n",
    "    return -scores.mean()\n",
    "\n",
    "ridge_space = \"alpha ~ loguniform[1e-4, 1e3]\"\n",
    "ridge_study = optuna.create_study(direction=\"minimize\", study_name=\"ridge_opt\")\n",
    "ridge_study.optimize(ridge_objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "best_alpha_ridge = ridge_study.best_params[\"alpha\"]\n",
    "\n",
    "ridge_best = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=best_alpha_ridge, random_state=SEED))\n",
    "])\n",
    "# Validación entrenando en X_tr\n",
    "ridge_best.fit(X_tr, y_tr)\n",
    "y_val_pred = ridge_best.predict(X_val)\n",
    "val_metrics = metrics_dict(y_val, y_val_pred)\n",
    "\n",
    "# Test refiteado en todo el train\n",
    "ridge_refit = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=best_alpha_ridge, random_state=SEED))\n",
    "])\n",
    "ridge_refit.fit(X_full, y_full)\n",
    "y_test_pred = ridge_refit.predict(X_test_ready)\n",
    "test_metrics = metrics_dict(np.ravel(y_test), y_test_pred)\n",
    "\n",
    "append_log({\n",
    "    **base_log_ctx,\n",
    "    \"model_name\": \"Ridge (Optuna)\",\n",
    "    \"params_json\": json.dumps({\"alpha\": float(best_alpha_ridge)}),\n",
    "    \"search_space_str\": ridge_space + f\"; n_trials={N_TRIALS}\",\n",
    "    \"val_mae\": val_metrics[\"mae\"],\n",
    "    \"val_rmse\": val_metrics[\"rmse\"],\n",
    "    \"val_r2\": val_metrics[\"r2\"],\n",
    "    \"test_mae\": test_metrics[\"mae\"],\n",
    "    \"test_rmse\": test_metrics[\"rmse\"],\n",
    "    \"test_r2\": test_metrics[\"r2\"],\n",
    "}, LOG_PATH)\n",
    "# MODIFICADO: Guardamos test_metrics[\"mae\"]\n",
    "all_results.append((\"Ridge (Optuna)\", test_metrics[\"mae\"], ridge_best, ridge_refit, y_val_pred, y_test_pred))\n",
    "\n",
    "# (e) Lasso — Optuna\n",
    "def lasso_objective(trial: optuna.Trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-4, 1e2, log=True)\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lasso\", Lasso(alpha=alpha, random_state=SEED, max_iter=10000))\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X_full, y_full, cv=tscv,\n",
    "                             scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "lasso_space = \"alpha ~ loguniform[1e-4, 1e2]\"\n",
    "lasso_study = optuna.create_study(direction=\"minimize\", study_name=\"lasso_opt\")\n",
    "lasso_study.optimize(lasso_objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "best_alpha_lasso = lasso_study.best_params[\"alpha\"]\n",
    "\n",
    "lasso_best = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso\", Lasso(alpha=best_alpha_lasso, random_state=SEED, max_iter=10000))\n",
    "])\n",
    "lasso_best.fit(X_tr, y_tr)\n",
    "y_val_pred = lasso_best.predict(X_val)\n",
    "val_metrics = metrics_dict(y_val, y_val_pred)\n",
    "\n",
    "lasso_refit = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso\", Lasso(alpha=best_alpha_lasso, random_state=SEED, max_iter=10000))\n",
    "])\n",
    "lasso_refit.fit(X_full, y_full)\n",
    "y_test_pred = lasso_refit.predict(X_test_ready)\n",
    "test_metrics = metrics_dict(np.ravel(y_test), y_test_pred)\n",
    "\n",
    "append_log({\n",
    "    **base_log_ctx,\n",
    "    \"model_name\": \"Lasso (Optuna)\",\n",
    "    \"params_json\": json.dumps({\"alpha\": float(best_alpha_lasso)}),\n",
    "    \"search_space_str\": lasso_space + f\"; n_trials={N_TRIALS}\",\n",
    "    \"val_mae\": val_metrics[\"mae\"],\n",
    "    \"val_rmse\": val_metrics[\"rmse\"],\n",
    "    \"val_r2\": val_metrics[\"r2\"],\n",
    "    \"test_mae\": test_metrics[\"mae\"],\n",
    "    \"test_rmse\": test_metrics[\"rmse\"],\n",
    "    \"test_r2\": test_metrics[\"r2\"],\n",
    "}, LOG_PATH)\n",
    "# MODIFICADO: Guardamos test_metrics[\"mae\"]\n",
    "all_results.append((\"Lasso (Optuna)\", test_metrics[\"mae\"], lasso_best, lasso_refit, y_val_pred, y_test_pred))\n",
    "\n",
    "# =========================\n",
    "# 3) Selección por MAE de TEST + gráficos y FI\n",
    "# =========================\n",
    "# all_results: (name, test_mae, model_val_fitted, model_test_refit, y_val_pred, y_test_pred)\n",
    "all_results.sort(key=lambda t: t[1]) # Ordena de menor a mayor (MAE menor es mejor)\n",
    "best_name, best_test_mae, best_model_val, best_model_full, best_yval_pred, best_ytest_pred = all_results[0]\n",
    "\n",
    "print(f\"\\n>>> Mejor modelo seleccionado por MAE en Test: {best_name} (Test MAE={best_test_mae:.4f})\")\n",
    "\n",
    "# Plots (validación y test) para el mejor\n",
    "# Validación\n",
    "plot_pred_vs_true(\n",
    "    y_true=y_val, y_pred=best_yval_pred,\n",
    "    title=f\"{best_name} - Validación\",\n",
    "    out_path=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_val_pred_vs_true.png\"\n",
    ")\n",
    "plot_residuals(\n",
    "    y_true=y_val, y_pred=best_yval_pred,\n",
    "    title=f\"{best_name} - Validación\",\n",
    "    out_path_scatter=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_val_resid_scatter.png\",\n",
    "    out_path_hist=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_val_resid_hist.png\"\n",
    ")\n",
    "\n",
    "# Test\n",
    "plot_pred_vs_true(\n",
    "    y_true=np.ravel(y_test), y_pred=best_ytest_pred,\n",
    "    title=f\"{best_name} - Test\",\n",
    "    out_path=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_test_pred_vs_true.png\"\n",
    ")\n",
    "plot_residuals(\n",
    "    y_true=np.ravel(y_test), y_pred=best_ytest_pred,\n",
    "    title=f\"{best_name} - Test\",\n",
    "    out_path_scatter=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_test_resid_scatter.png\",\n",
    "    out_path_hist=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_test_resid_hist.png\"\n",
    ")\n",
    "\n",
    "# Feature importance del mejor (en el modelo refiteado full)\n",
    "save_feature_importance(\n",
    "    best_model_full,\n",
    "    feature_names=X_train_ready.columns.tolist(),\n",
    "    out_csv=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_feature_importance.csv\",\n",
    "    out_png=RESULTS_DIR / f\"{TS}_{best_name.replace(' ','_')}_feature_importance.png\",\n",
    "    top_k=30\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 4) Resumen de experimentos (MD)\n",
    "# =========================\n",
    "summary_md_path = RESULTS_DIR / f\"experiment_summary_{TS}.md\"\n",
    "write_summary_md(LOG_PATH, summary_md_path)\n",
    "\n",
    "print(\"\\n==== Listo ====\")\n",
    "print(f\"- Logs: {LOG_PATH}\")\n",
    "print(f\"- Resumen: {summary_md_path}\")\n",
    "print(f\"- Gráficos y FI en: {RESULTS_DIR}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trabajo-Final-Lab-Datos- (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
