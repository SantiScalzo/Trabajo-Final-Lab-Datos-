{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0233c188",
   "metadata": {},
   "source": [
    "Una vez que creamos el primer dataset, vamos a dividirlo en train y test, tratar los valores nulos y outliers y hacer el shift para tener nuestros datos listos para ser usados por un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39d6ddc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2020-07-01 23:59:00\n",
       "1     2020-07-02 23:59:00\n",
       "2     2020-07-03 23:59:00\n",
       "3     2020-07-04 23:59:00\n",
       "4     2020-07-05 23:59:00\n",
       "              ...        \n",
       "954   2023-03-01 23:59:00\n",
       "955   2023-03-02 23:59:00\n",
       "956   2023-03-03 23:59:00\n",
       "957   2023-03-04 23:59:00\n",
       "958   2023-03-05 23:59:00\n",
       "Name: FECHA_HORA, Length: 959, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos a leer foundational_dataset.csv y definir el y \n",
    "import pandas as pd\n",
    "df_final=pd.read_csv(\"foundational_dataset.csv\")\n",
    "\n",
    "#quiero ordenar los datos segun FECHA_HORA\n",
    "df_final[\"FECHA_HORA\"] = pd.to_datetime(\n",
    "    df_final[\"FECHA_HORA\"].astype(str),  # asegúrate de que los datos sean strings\n",
    "    errors=\"coerce\",      # marca inválidos como NaT\n",
    "    # format=\"...\"        # si conoces el formato exacto, mejor especificarlo\n",
    ")\n",
    "df_final = df_final.sort_values(\"FECHA_HORA\", ascending=True, na_position=\"last\")\n",
    "\n",
    "df_final[\"FECHA_HORA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_final[\"Frio_diff1_lag1\"] = df_final[\"Frio (Kw)\"].astype(float).diff().shift(1)\n",
    "df_final[\"Frio_diff7_lag1\"] = df_final[\"Frio (Kw)\"].astype(float).diff().shift(1)\n",
    "roll_windows = [3, 7, 14,28]\n",
    "for window in roll_windows:\n",
    "    df_final[f\"Frio_roll_mean_{window}_lag1\"] = df_final[\"Frio (Kw)\"].astype(float).shift(1).rolling(window=window).mean()\n",
    "    df_final[f\"Frio_roll_std_{window}_lag1\"] = df_final[\"Frio (Kw)\"].astype(float).shift(1).rolling(window=window).std()\n",
    "\n",
    "\n",
    "\n",
    "y = df_final[\"Frio (Kw)\"].shift(-1)  # predecir el siguiente valor de Frio (Kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01f65664",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dropna(inplace=True)\n",
    "X = df_final.loc[y.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7108ba20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_HORA</th>\n",
       "      <th>EE Planta / Hl</th>\n",
       "      <th>EE Elaboracion / Hl</th>\n",
       "      <th>EE Bodega / Hl</th>\n",
       "      <th>EE Cocina / Hl</th>\n",
       "      <th>EE Envasado / Hl</th>\n",
       "      <th>EE Linea 2 / Hl</th>\n",
       "      <th>EE Linea 3 / Hl</th>\n",
       "      <th>EE Linea 4 / Hl</th>\n",
       "      <th>EE Servicios / Hl</th>\n",
       "      <th>...</th>\n",
       "      <th>Frio_diff1_lag1</th>\n",
       "      <th>Frio_diff7_lag1</th>\n",
       "      <th>Frio_roll_mean_3_lag1</th>\n",
       "      <th>Frio_roll_std_3_lag1</th>\n",
       "      <th>Frio_roll_mean_7_lag1</th>\n",
       "      <th>Frio_roll_std_7_lag1</th>\n",
       "      <th>Frio_roll_mean_14_lag1</th>\n",
       "      <th>Frio_roll_std_14_lag1</th>\n",
       "      <th>Frio_roll_mean_28_lag1</th>\n",
       "      <th>Frio_roll_std_28_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01 23:59:00</td>\n",
       "      <td>642.727209</td>\n",
       "      <td>47.145349</td>\n",
       "      <td>69.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.813953</td>\n",
       "      <td>14.578784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>554.604651</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-02 23:59:00</td>\n",
       "      <td>7.767254</td>\n",
       "      <td>0.769609</td>\n",
       "      <td>0.798838</td>\n",
       "      <td>0.319229</td>\n",
       "      <td>2.358593</td>\n",
       "      <td>4.158962</td>\n",
       "      <td>1.506838</td>\n",
       "      <td>1.521823</td>\n",
       "      <td>5.429388</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-03 23:59:00</td>\n",
       "      <td>8.801205</td>\n",
       "      <td>0.862593</td>\n",
       "      <td>0.835762</td>\n",
       "      <td>0.260924</td>\n",
       "      <td>1.985462</td>\n",
       "      <td>39.076667</td>\n",
       "      <td>1.448962</td>\n",
       "      <td>1.500923</td>\n",
       "      <td>5.703346</td>\n",
       "      <td>...</td>\n",
       "      <td>9629.000000</td>\n",
       "      <td>9629.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-04 23:59:00</td>\n",
       "      <td>5.175639</td>\n",
       "      <td>0.439225</td>\n",
       "      <td>0.371077</td>\n",
       "      <td>0.258048</td>\n",
       "      <td>1.442114</td>\n",
       "      <td>4.348182</td>\n",
       "      <td>1.355238</td>\n",
       "      <td>1.536507</td>\n",
       "      <td>3.058399</td>\n",
       "      <td>...</td>\n",
       "      <td>4314.000000</td>\n",
       "      <td>4314.000000</td>\n",
       "      <td>22182.333333</td>\n",
       "      <td>7138.341147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-05 23:59:00</td>\n",
       "      <td>7.924665</td>\n",
       "      <td>0.802365</td>\n",
       "      <td>0.717787</td>\n",
       "      <td>0.301592</td>\n",
       "      <td>1.664726</td>\n",
       "      <td>5.125920</td>\n",
       "      <td>2.704348</td>\n",
       "      <td>1.471990</td>\n",
       "      <td>5.094301</td>\n",
       "      <td>...</td>\n",
       "      <td>-4022.000000</td>\n",
       "      <td>-4022.000000</td>\n",
       "      <td>25489.333333</td>\n",
       "      <td>2410.820884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>2023-02-28 23:59:00</td>\n",
       "      <td>5.771037</td>\n",
       "      <td>0.764416</td>\n",
       "      <td>0.585371</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>1.560490</td>\n",
       "      <td>4.493845</td>\n",
       "      <td>1.536465</td>\n",
       "      <td>1.513804</td>\n",
       "      <td>3.056305</td>\n",
       "      <td>...</td>\n",
       "      <td>-3781.000000</td>\n",
       "      <td>-3781.000000</td>\n",
       "      <td>18126.000000</td>\n",
       "      <td>2250.100220</td>\n",
       "      <td>18942.571429</td>\n",
       "      <td>2104.955966</td>\n",
       "      <td>18097.714286</td>\n",
       "      <td>2628.882021</td>\n",
       "      <td>18390.892857</td>\n",
       "      <td>2510.380838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>2023-03-01 23:59:00</td>\n",
       "      <td>6.960582</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.715616</td>\n",
       "      <td>0.356634</td>\n",
       "      <td>1.829548</td>\n",
       "      <td>4.289280</td>\n",
       "      <td>1.696989</td>\n",
       "      <td>1.547479</td>\n",
       "      <td>3.765249</td>\n",
       "      <td>...</td>\n",
       "      <td>6225.666667</td>\n",
       "      <td>6225.666667</td>\n",
       "      <td>18866.555556</td>\n",
       "      <td>3136.645808</td>\n",
       "      <td>19700.809524</td>\n",
       "      <td>2010.878589</td>\n",
       "      <td>18494.261905</td>\n",
       "      <td>2737.873035</td>\n",
       "      <td>18531.130952</td>\n",
       "      <td>2586.413840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2023-03-02 23:59:00</td>\n",
       "      <td>9.307652</td>\n",
       "      <td>1.326883</td>\n",
       "      <td>1.062212</td>\n",
       "      <td>0.323571</td>\n",
       "      <td>1.221995</td>\n",
       "      <td>7.212923</td>\n",
       "      <td>9.078431</td>\n",
       "      <td>2.206813</td>\n",
       "      <td>6.167811</td>\n",
       "      <td>...</td>\n",
       "      <td>1690.333333</td>\n",
       "      <td>1690.333333</td>\n",
       "      <td>20244.888889</td>\n",
       "      <td>4168.916890</td>\n",
       "      <td>20144.666667</td>\n",
       "      <td>2466.715450</td>\n",
       "      <td>18930.904762</td>\n",
       "      <td>3012.302250</td>\n",
       "      <td>18533.488095</td>\n",
       "      <td>2591.023465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>2023-03-03 23:59:00</td>\n",
       "      <td>10.349507</td>\n",
       "      <td>1.383240</td>\n",
       "      <td>1.289095</td>\n",
       "      <td>0.360673</td>\n",
       "      <td>0.524170</td>\n",
       "      <td>16.664444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>7.930706</td>\n",
       "      <td>...</td>\n",
       "      <td>-4591.000000</td>\n",
       "      <td>-4591.000000</td>\n",
       "      <td>21353.222222</td>\n",
       "      <td>2321.937944</td>\n",
       "      <td>19882.952381</td>\n",
       "      <td>2496.467530</td>\n",
       "      <td>18919.190476</td>\n",
       "      <td>3012.248005</td>\n",
       "      <td>18467.738095</td>\n",
       "      <td>2557.226902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>2023-03-04 23:59:00</td>\n",
       "      <td>5.403903</td>\n",
       "      <td>0.556676</td>\n",
       "      <td>0.351268</td>\n",
       "      <td>0.344653</td>\n",
       "      <td>1.502742</td>\n",
       "      <td>3.514023</td>\n",
       "      <td>1.691494</td>\n",
       "      <td>1.491764</td>\n",
       "      <td>2.904113</td>\n",
       "      <td>...</td>\n",
       "      <td>-8582.000000</td>\n",
       "      <td>-8582.000000</td>\n",
       "      <td>17525.666667</td>\n",
       "      <td>6686.502997</td>\n",
       "      <td>18387.380952</td>\n",
       "      <td>4346.056592</td>\n",
       "      <td>18694.761905</td>\n",
       "      <td>3526.889597</td>\n",
       "      <td>18139.130952</td>\n",
       "      <td>2979.331939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FECHA_HORA  EE Planta / Hl  EE Elaboracion / Hl  EE Bodega / Hl  \\\n",
       "0   2020-07-01 23:59:00      642.727209            47.145349       69.023256   \n",
       "1   2020-07-02 23:59:00        7.767254             0.769609        0.798838   \n",
       "2   2020-07-03 23:59:00        8.801205             0.862593        0.835762   \n",
       "3   2020-07-04 23:59:00        5.175639             0.439225        0.371077   \n",
       "4   2020-07-05 23:59:00        7.924665             0.802365        0.717787   \n",
       "..                  ...             ...                  ...             ...   \n",
       "953 2023-02-28 23:59:00        5.771037             0.764416        0.585371   \n",
       "954 2023-03-01 23:59:00        6.960582             0.907813        0.715616   \n",
       "955 2023-03-02 23:59:00        9.307652             1.326883        1.062212   \n",
       "956 2023-03-03 23:59:00       10.349507             1.383240        1.289095   \n",
       "957 2023-03-04 23:59:00        5.403903             0.556676        0.351268   \n",
       "\n",
       "     EE Cocina / Hl  EE Envasado / Hl  EE Linea 2 / Hl  EE Linea 3 / Hl  \\\n",
       "0          0.000000         13.813953        14.578784         0.000000   \n",
       "1          0.319229          2.358593         4.158962         1.506838   \n",
       "2          0.260924          1.985462        39.076667         1.448962   \n",
       "3          0.258048          1.442114         4.348182         1.355238   \n",
       "4          0.301592          1.664726         5.125920         2.704348   \n",
       "..              ...               ...              ...              ...   \n",
       "953        0.313305          1.560490         4.493845         1.536465   \n",
       "954        0.356634          1.829548         4.289280         1.696989   \n",
       "955        0.323571          1.221995         7.212923         9.078431   \n",
       "956        0.360673          0.524170        16.664444              NaN   \n",
       "957        0.344653          1.502742         3.514023         1.691494   \n",
       "\n",
       "     EE Linea 4 / Hl  EE Servicios / Hl  ...  Frio_diff1_lag1  \\\n",
       "0           0.000000         554.604651  ...              NaN   \n",
       "1           1.521823           5.429388  ...              NaN   \n",
       "2           1.500923           5.703346  ...      9629.000000   \n",
       "3           1.536507           3.058399  ...      4314.000000   \n",
       "4           1.471990           5.094301  ...     -4022.000000   \n",
       "..               ...                ...  ...              ...   \n",
       "953         1.513804           3.056305  ...     -3781.000000   \n",
       "954         1.547479           3.765249  ...      6225.666667   \n",
       "955         2.206813           6.167811  ...      1690.333333   \n",
       "956         9.750000           7.930706  ...     -4591.000000   \n",
       "957         1.491764           2.904113  ...     -8582.000000   \n",
       "\n",
       "     Frio_diff7_lag1  Frio_roll_mean_3_lag1  Frio_roll_std_3_lag1  \\\n",
       "0                NaN                    NaN                   NaN   \n",
       "1                NaN                    NaN                   NaN   \n",
       "2        9629.000000                    NaN                   NaN   \n",
       "3        4314.000000           22182.333333           7138.341147   \n",
       "4       -4022.000000           25489.333333           2410.820884   \n",
       "..               ...                    ...                   ...   \n",
       "953     -3781.000000           18126.000000           2250.100220   \n",
       "954      6225.666667           18866.555556           3136.645808   \n",
       "955      1690.333333           20244.888889           4168.916890   \n",
       "956     -4591.000000           21353.222222           2321.937944   \n",
       "957     -8582.000000           17525.666667           6686.502997   \n",
       "\n",
       "     Frio_roll_mean_7_lag1  Frio_roll_std_7_lag1  Frio_roll_mean_14_lag1  \\\n",
       "0                      NaN                   NaN                     NaN   \n",
       "1                      NaN                   NaN                     NaN   \n",
       "2                      NaN                   NaN                     NaN   \n",
       "3                      NaN                   NaN                     NaN   \n",
       "4                      NaN                   NaN                     NaN   \n",
       "..                     ...                   ...                     ...   \n",
       "953           18942.571429           2104.955966            18097.714286   \n",
       "954           19700.809524           2010.878589            18494.261905   \n",
       "955           20144.666667           2466.715450            18930.904762   \n",
       "956           19882.952381           2496.467530            18919.190476   \n",
       "957           18387.380952           4346.056592            18694.761905   \n",
       "\n",
       "     Frio_roll_std_14_lag1  Frio_roll_mean_28_lag1  Frio_roll_std_28_lag1  \n",
       "0                      NaN                     NaN                    NaN  \n",
       "1                      NaN                     NaN                    NaN  \n",
       "2                      NaN                     NaN                    NaN  \n",
       "3                      NaN                     NaN                    NaN  \n",
       "4                      NaN                     NaN                    NaN  \n",
       "..                     ...                     ...                    ...  \n",
       "953            2628.882021            18390.892857            2510.380838  \n",
       "954            2737.873035            18531.130952            2586.413840  \n",
       "955            3012.302250            18533.488095            2591.023465  \n",
       "956            3012.248005            18467.738095            2557.226902  \n",
       "957            3526.889597            18139.130952            2979.331939  \n",
       "\n",
       "[958 rows x 141 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84c486a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 864 registros (90.1%)\n",
      "  Fechas: 2020-07-01 23:59:00 a 2022-11-29 23:59:00\n",
      "\n",
      "Test: 94 registros (9.8%)\n",
      "  Fechas: 2022-11-30 23:59:00 a 2023-03-04 23:59:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Calcular el punto de corte (10% más antiguo = test)\n",
    "n_test = int(len(df_final) * 0.10)\n",
    "n_train = len(df_final) - n_test\n",
    "\n",
    "# Split temporal\n",
    "\n",
    "x_test = X.iloc[n_train:].copy()\n",
    "x_train = X.iloc[:n_train].copy()\n",
    "y_test = y.iloc[n_train:].copy()\n",
    "y_train = y.iloc[:n_train].copy()\n",
    "print(f\"\\nTrain: {len(x_train)} registros ({len(x_train)/len(df_final)*100:.1f}%)\")\n",
    "print(f\"  Fechas: {x_train['FECHA_HORA'].min()} a {x_train['FECHA_HORA'].max()}\")\n",
    "print(f\"\\nTest: {len(x_test)} registros ({len(x_test)/len(df_final)*100:.1f}%)\")\n",
    "print(f\"  Fechas: {x_test['FECHA_HORA'].min()} a {x_test['FECHA_HORA'].max()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38878674",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns=[\"FECHA_HORA\"], inplace=True)\n",
    "x_test.drop(columns=[\"FECHA_HORA\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39ab6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas numéricas para LOF: 100.00% (140 columnas)\n",
      "\n",
      "Outliers detectados en TRAIN: 44 (5.09%)\n",
      "Outliers detectados en TEST: 6 (6.38%)\n",
      "\n",
      "✓ Outliers marcados como NaN\n",
      "  Train - NaN totales: 9841\n",
      "  Test - NaN totales: 1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agusm\\Trabajo-Final-Lab-Datos-\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# DETECCIÓN DE OUTLIERS CON LOCAL OUTLIER FACTOR\n",
    "\n",
    "# Guardar datos originales\n",
    "X_train_original = x_train.copy()\n",
    "\n",
    "X_test_original = x_test.copy()\n",
    "\n",
    "#vamos a estandarizar los datos antes de aplicar LOF\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test_scaled = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "\n",
    "\n",
    "# Seleccionar solo columnas numéricas para LOF\n",
    "numeric_cols = x_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nColumnas numéricas para LOF: {len(numeric_cols) / len(x_train.columns)*100:.2f}% ({len(numeric_cols)} columnas)\")\n",
    "\n",
    "# Manejar NaN antes de LOF (LOF no acepta NaN)\n",
    "train_for_lof = x_train_scaled[numeric_cols].fillna(x_train_scaled[numeric_cols].median())\n",
    "test_for_lof = x_test_scaled[numeric_cols].fillna(x_train_scaled[numeric_cols].median())\n",
    "\n",
    "# Ajustar LOF en train\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "train_outliers = lof.fit_predict(train_for_lof)\n",
    "\n",
    "# Aplicar LOF en test (usando fit de train)\n",
    "# LOF no tiene predict, usamos fit_predict con novelty=True\n",
    "lof_novelty = LocalOutlierFactor(n_neighbors=20, contamination=0.05, novelty=True)\n",
    "lof_novelty.fit(train_for_lof)\n",
    "test_outliers = lof_novelty.predict(test_for_lof)\n",
    "\n",
    "# Contar outliers (-1 = outlier, 1 = inlier)\n",
    "n_train_outliers = (train_outliers == -1).sum()\n",
    "n_test_outliers = (test_outliers == -1).sum()\n",
    "\n",
    "print(f\"\\nOutliers detectados en TRAIN: {n_train_outliers} ({n_train_outliers/len(x_train)*100:.2f}%)\")\n",
    "print(f\"Outliers detectados en TEST: {n_test_outliers} ({n_test_outliers/len(x_test)*100:.2f}%)\")\n",
    "\n",
    "# Marcar outliers como NaN en TODAS las columnas numéricas\n",
    "train_with_outliers = x_train.copy()\n",
    "test_with_outliers = x_test.copy()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    train_with_outliers.loc[train_outliers == -1, col] = np.nan\n",
    "    test_with_outliers.loc[test_outliers == -1, col] = np.nan\n",
    "\n",
    "print(f\"\\n✓ Outliers marcados como NaN\")\n",
    "print(f\"  Train - NaN totales: {train_with_outliers.isna().sum().sum()}\")\n",
    "print(f\"  Test - NaN totales: {test_with_outliers.isna().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f441d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "037eb0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4. IMPUTACIÓN DE VALORES NULOS CON KNN\n",
      "================================================================================\n",
      "\n",
      "NaN antes de imputación:\n",
      "  Train: 9841\n",
      "  Test: 1820\n",
      "\n",
      "✓ Imputación completada\n",
      "  Train - NaN restantes: 0\n",
      "  Test - NaN restantes: 0\n",
      "✅ Archivo 'x_train.csv' guardado correctamente.\n",
      "✅ Archivo 'x_val.csv' guardado correctamente.\n",
      "✅ Archivo 'y_train.csv' guardado correctamente.\n",
      "✅ Archivo 'y_val.csv' guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPUTACIÓN CON KNN REGRESSOR\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4. IMPUTACIÓN DE VALORES NULOS CON KNN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Contar NaN antes de imputación\n",
    "print(f\"\\nNaN antes de imputación:\")\n",
    "print(f\"  Train: {train_with_outliers[numeric_cols].isna().sum().sum()}\")\n",
    "print(f\"  Test: {test_with_outliers[numeric_cols].isna().sum().sum()}\")\n",
    "\n",
    "# Configurar KNN Imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Ajustar en train e imputar\n",
    "train_imputed_numeric = knn_imputer.fit_transform(train_with_outliers[numeric_cols])\n",
    "train_imputed = train_with_outliers.copy()\n",
    "train_imputed[numeric_cols] = train_imputed_numeric\n",
    "\n",
    "# Aplicar en test\n",
    "test_imputed_numeric = knn_imputer.transform(test_with_outliers[numeric_cols])\n",
    "test_imputed = test_with_outliers.copy()\n",
    "test_imputed[numeric_cols] = test_imputed_numeric\n",
    "\n",
    "print(f\"\\n✓ Imputación completada\")\n",
    "print(f\"  Train - NaN restantes: {train_imputed.isna().sum().sum()}\")\n",
    "print(f\"  Test - NaN restantes: {test_imputed.isna().sum().sum()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def descargar_dataframe_como_csv(df, nombre_archivo):\n",
    "    try:\n",
    "        df.to_csv(nombre_archivo, index=False)\n",
    "        print(f\"✅ Archivo '{nombre_archivo}' guardado correctamente.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ocurrió un error al guardar el archivo: {e}\")\n",
    "\n",
    "descargar_dataframe_como_csv(train_imputed, \"x_train.csv\")\n",
    "descargar_dataframe_como_csv(test_imputed, \"x_val.csv\")\n",
    "descargar_dataframe_como_csv(y_train.to_frame(), \"y_train.csv\")\n",
    "descargar_dataframe_como_csv(y_test.to_frame(), \"y_val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba93b8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. ESTADÍSTICAS DESCRIPTIVAS - TRAIN\n",
      "================================================================================\n",
      "\n",
      "Estadísticas básicas:\n",
      "       EE Planta / Hl  EE Elaboracion / Hl  EE Bodega / Hl  EE Cocina / Hl  \\\n",
      "count          864.00               864.00          864.00          864.00   \n",
      "mean             8.00                 0.87            0.77            0.32   \n",
      "std              3.41                 0.45            0.50            0.16   \n",
      "min              3.60                 0.27           -0.45            0.00   \n",
      "25%              6.27                 0.66            0.55            0.27   \n",
      "50%              7.23                 0.78            0.66            0.30   \n",
      "75%              8.31                 0.92            0.80            0.33   \n",
      "max             53.21                 7.10            6.99            2.27   \n",
      "\n",
      "       EE Envasado / Hl  EE Linea 2 / Hl  EE Linea 3 / Hl  EE Linea 4 / Hl  \\\n",
      "count            864.00           864.00           864.00           864.00   \n",
      "mean               1.72             6.21             1.78             1.60   \n",
      "std                0.72             9.82             0.98             0.52   \n",
      "min                0.08            -0.09             0.00             0.00   \n",
      "25%                1.38             2.33             1.48             1.46   \n",
      "50%                1.63             3.54             1.72             1.55   \n",
      "75%                1.89             5.66             2.05             1.69   \n",
      "max                5.91            88.66             9.79             6.96   \n",
      "\n",
      "       EE Servicios / Hl  EE Sala Maq / Hl  ...  Frio_diff1_lag1  \\\n",
      "count             864.00            864.00  ...           864.00   \n",
      "mean                4.96              3.41  ...           130.41   \n",
      "std                 2.46              1.75  ...          4339.21   \n",
      "min                 1.24              0.60  ...        -16160.00   \n",
      "25%                 3.83              2.61  ...         -2461.00   \n",
      "50%                 4.45              3.08  ...           130.20   \n",
      "75%                 5.13              3.66  ...          2445.00   \n",
      "max                36.54             25.81  ...         24484.00   \n",
      "\n",
      "       Frio_diff7_lag1  Frio_roll_mean_3_lag1  Frio_roll_std_3_lag1  \\\n",
      "count           864.00                 864.00                864.00   \n",
      "mean            130.41               24633.86               2855.53   \n",
      "std            4339.21                7268.40               1859.30   \n",
      "min          -16160.00                2728.67                 67.10   \n",
      "25%           -2461.00               19854.42               1606.19   \n",
      "50%             130.20               24832.50               2599.34   \n",
      "75%            2445.00               30050.25               3635.74   \n",
      "max           24484.00               43592.67              14848.98   \n",
      "\n",
      "       Frio_roll_mean_7_lag1  Frio_roll_std_7_lag1  Frio_roll_mean_14_lag1  \\\n",
      "count                 864.00                864.00                  864.00   \n",
      "mean                24678.55               3545.16                26636.10   \n",
      "std                  6962.03               1503.38                19799.84   \n",
      "min                  5054.43                542.91                 8160.43   \n",
      "25%                 19873.71               2590.51                19819.36   \n",
      "50%                 25213.21               3437.92                26225.18   \n",
      "75%                 29587.36               4114.53                29864.89   \n",
      "max                 38286.29               9860.26               229256.86   \n",
      "\n",
      "       Frio_roll_std_14_lag1  Frio_roll_mean_28_lag1  Frio_roll_std_28_lag1  \n",
      "count                 864.00                  864.00                 864.00  \n",
      "mean                10883.09                27654.13               19136.40  \n",
      "std                 67062.34                17706.82               81403.67  \n",
      "min                  1360.94                10127.18                1998.99  \n",
      "25%                  3036.38                20035.33                3426.66  \n",
      "50%                  3657.35                26287.89                3954.44  \n",
      "75%                  4637.64                30300.46                5134.99  \n",
      "max                741478.43               130162.04              524374.99  \n",
      "\n",
      "[8 rows x 140 columns]\n",
      "\n",
      "================================================================================\n",
      "INFORMACIÓN ADICIONAL\n",
      "================================================================================\n",
      "\n",
      "Shape: (864, 140)\n",
      "Columnas numéricas: 140\n",
      "Valores nulos: 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ASIMETRÍA (Skewness) Y CURTOSIS\n",
      "--------------------------------------------------------------------------------\n",
      "                        Skewness  Kurtosis\n",
      "Calderas (Kw)              28.72    837.58\n",
      "EE Caldera / Hl            26.05    731.99\n",
      "EE Resto Planta / Hl       11.34    263.68\n",
      "Frio_roll_std_14_lag1      10.58    112.14\n",
      "ET Linea 2/Hl               9.00    105.65\n",
      "Frio_roll_mean_14_lag1      8.68     86.03\n",
      "Aire Cocina / Hl            7.50     72.51\n",
      "Restos Planta (Kw)          7.46    148.38\n",
      "Agua Linea 3/Hl             7.27     98.04\n",
      "FC Lavadora L2              7.13     49.07\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 2. DISTRIBUCIÓN DE LA VARIABLE OBJETIVO\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m2. ANÁLISIS DE LA VARIABLE OBJETIVO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtarget_col\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     48\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'target_col' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Configuración de estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. ESTADÍSTICAS DESCRIPTIVAS GENERALES\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"1. ESTADÍSTICAS DESCRIPTIVAS - TRAIN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estadísticas básicas\n",
    "desc_stats = train_imputed[numeric_cols].describe()\n",
    "print(\"\\nEstadísticas básicas:\")\n",
    "print(desc_stats.round(2))\n",
    "\n",
    "# Información adicional\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INFORMACIÓN ADICIONAL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShape: {train_imputed.shape}\")\n",
    "print(f\"Columnas numéricas: {len(numeric_cols)}\")\n",
    "print(f\"Valores nulos: {train_imputed.isna().sum().sum()}\")\n",
    "\n",
    "# Asimetría y curtosis\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"ASIMETRÍA (Skewness) Y CURTOSIS\")\n",
    "print(\"-\" * 80)\n",
    "skew_kurt = pd.DataFrame({\n",
    "    'Skewness': train_imputed[numeric_cols].skew(),\n",
    "    'Kurtosis': train_imputed[numeric_cols].kurtosis()\n",
    "}).round(2)\n",
    "print(skew_kurt.sort_values('Skewness', ascending=False).head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DISTRIBUCIÓN DE LA VARIABLE OBJETIVO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"2. ANÁLISIS DE LA VARIABLE OBJETIVO: {target_col}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(f'Análisis de {target_col}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Histograma\n",
    "axes[0, 0].hist(y_train, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(y_train.mean(), color='red', \n",
    "                    linestyle='--', linewidth=2, label=f'Media: {y_train.mean():.2f}')\n",
    "axes[0, 0].axvline(y_train.median(), color='green', \n",
    "                    linestyle='--', linewidth=2, label=f'Mediana: {y_train.median():.2f}')\n",
    "axes[0, 0].set_xlabel(target_col)\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].set_title('Histograma')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "bp = axes[0, 1].boxplot(y_train, vert=True, patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "axes[0, 1].set_ylabel(target_col)\n",
    "axes[0, 1].set_title('Box Plot')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(y_train, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot (Normalidad)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparación Train vs Test\n",
    "axes[1, 1].hist(y_train, bins=30, alpha=0.6, \n",
    "                label=f'Train (μ={y_train.mean():.2f})', edgecolor='black')\n",
    "axes[1, 1].hist(y_test, bins=30, alpha=0.6, \n",
    "                label=f'Test (μ={y_test.mean():.2f})', edgecolor='black')\n",
    "axes[1, 1].set_xlabel(target_col)\n",
    "axes[1, 1].set_ylabel('Frecuencia')\n",
    "axes[1, 1].set_title('Comparación Train vs Test')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas detalladas del target\n",
    "print(f\"\\nEstadísticas de {target_col}:\")\n",
    "print(f\"  Media: {y_train.mean():.2f}\")\n",
    "print(f\"  Mediana: {y_train.median():.2f}\")\n",
    "print(f\"  Desv. Std: {y_train.std():.2f}\")\n",
    "print(f\"  Min: {y_train.min():.2f}\")\n",
    "print(f\"  Max: {y_train.max():.2f}\")\n",
    "print(f\"  Skewness: {y_train.skew():.2f}\")\n",
    "print(f\"  Kurtosis: {y_train.kurtosis():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. DISTRIBUCIÓN DE TODAS LAS VARIABLES NUMÉRICAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"3. DISTRIBUCIÓN DE VARIABLES NUMÉRICAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccionar top 20 variables por varianza\n",
    "vars_by_variance = train_imputed[numeric_cols].var().sort_values(ascending=False).head(20)\n",
    "top_vars = vars_by_variance.index.tolist()\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(top_vars) / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
    "fig.suptitle('Distribución de Top 20 Variables (por varianza)', fontsize=16, fontweight='bold')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(top_vars):\n",
    "    axes[idx].hist(train_imputed[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'{col}\\n(μ={train_imputed[col].mean():.2f}, σ={train_imputed[col].std():.2f})', \n",
    "                        fontsize=9)\n",
    "    axes[idx].set_xlabel('')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Ocultar ejes vacíos\n",
    "for idx in range(len(top_vars), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. MATRIZ DE CORRELACIÓN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4. ANÁLISIS DE CORRELACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular matriz de correlación\n",
    "corr_matrix = train_imputed[numeric_cols].corr()\n",
    "\n",
    "# Encontrar las correlaciones más altas con el target\n",
    "target_corr = corr_matrix[target_col].sort_values(ascending=False)\n",
    "print(f\"\\nTop 15 variables más correlacionadas con {target_col}:\")\n",
    "print(target_corr.head(15).round(3))\n",
    "\n",
    "# Visualizar matriz de correlación (top variables)\n",
    "top_corr_vars = target_corr.abs().sort_values(ascending=False).head(15).index\n",
    "corr_subset = train_imputed[top_corr_vars].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_subset, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(f'Matriz de Correlación - Top 15 variables correlacionadas con {target_col}', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 5. SCATTER PLOTS - RELACIÓN CON VARIABLE OBJETIVO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"5. SCATTER PLOTS - RELACIÓN CON TARGET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Top 8 variables más correlacionadas (excluyendo el target mismo)\n",
    "top_predictors = target_corr.drop(target_col).abs().sort_values(ascending=False).head(8).index\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.suptitle(f'Relación de Variables con {target_col}', fontsize=16, fontweight='bold')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, predictor in enumerate(top_predictors):\n",
    "    axes[idx].scatter(train_imputed[predictor], y_train, \n",
    "                     alpha=0.5, s=20, edgecolors='black', linewidths=0.5)\n",
    "    \n",
    "    # Línea de regresión\n",
    "    z = np.polyfit(train_imputed[predictor], y_train, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(train_imputed[predictor], p(train_imputed[predictor]), \n",
    "                   \"r--\", linewidth=2, alpha=0.8)\n",
    "    \n",
    "    corr_val = train_imputed[[predictor, target_col]].corr().iloc[0, 1]\n",
    "    axes[idx].set_xlabel(predictor, fontsize=9)\n",
    "    axes[idx].set_ylabel(target_col, fontsize=9)\n",
    "    axes[idx].set_title(f'Corr: {corr_val:.3f}', fontsize=10, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. BOX PLOTS COMPARATIVOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"6. BOX PLOTS - COMPARACIÓN DE DISTRIBUCIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Normalizar datos para comparación visual\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(train_imputed[top_vars]),\n",
    "    columns=top_vars\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "train_scaled.boxplot(rot=90, figsize=(20, 8))\n",
    "plt.title('Box Plots de Variables Normalizadas (Top 20 por varianza)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Valor Normalizado')\n",
    "plt.xlabel('Variables')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. RESUMEN ESTADÍSTICO POR GRUPOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"7. RESUMEN FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear tabla resumen\n",
    "summary_table = pd.DataFrame({\n",
    "    'Media': train_imputed[numeric_cols].mean(),\n",
    "    'Mediana': train_imputed[numeric_cols].median(),\n",
    "    'Std': train_imputed[numeric_cols].std(),\n",
    "    'Min': train_imputed[numeric_cols].min(),\n",
    "    'Max': train_imputed[numeric_cols].max(),\n",
    "    'Skew': train_imputed[numeric_cols].skew(),\n",
    "    'Corr_Target': corr_matrix[target_col]\n",
    "}).round(3)\n",
    "\n",
    "summary_table = summary_table.sort_values('Corr_Target', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 variables por correlación absoluta con target:\")\n",
    "print(summary_table.head(15))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ ANÁLISIS EXPLORATORIO COMPLETADO\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb2f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trabajo-Final-Lab-Datos- (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
